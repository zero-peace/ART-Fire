#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CPUä¸“ç”¨æ‰¹é‡é¢„æµ‹è„šæœ¬
ä¸“é—¨ç”¨äºGPUå†…å­˜ä¸è¶³çš„æƒ…å†µï¼Œå¼ºåˆ¶ä½¿ç”¨CPUè¿›è¡Œé¢„æµ‹
"""

import os
import sys
import torch
import gc
import time
from batch_predict import BatchPredictor

def get_memory_info():
    """è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.memory_allocated() / 1024**3  # GB
        gpu_memory_reserved = torch.cuda.memory_reserved() / 1024**3  # GB
        return f"GPU: {gpu_memory:.2f}GB (å·²åˆ†é…) / {gpu_memory_reserved:.2f}GB (å·²ä¿ç•™)"
    else:
        return "CPUæ¨¡å¼"

def force_memory_cleanup():
    """å¼ºåˆ¶å†…å­˜æ¸…ç†"""
    print("ğŸ§¹ æ‰§è¡Œå†…å­˜æ¸…ç†...")
    
    # æ¸…ç†GPUç¼“å­˜
    if torch.cuda.is_available():
        try:
            torch.cuda.empty_cache()
            print("  âœ“ GPUç¼“å­˜å·²æ¸…ç†")
        except Exception as e:
            print(f"  âš  GPUç¼“å­˜æ¸…ç†å¤±è´¥: {e}")
    
    # æ¸…ç†Pythonå†…å­˜
    try:
        gc.collect()
        print("  âœ“ Pythonå†…å­˜å·²æ¸…ç†")
    except Exception as e:
        print(f"  âš  Pythonå†…å­˜æ¸…ç†å¤±è´¥: {e}")

class CPUOnlyBatchPredictor:
    def __init__(self, model_path='Maple728/TimeMoE-200M'):
        """
        CPUä¸“ç”¨æ‰¹é‡é¢„æµ‹å™¨
        
        Args:
            model_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
        """
        print(f"ğŸ”§ åˆå§‹åŒ–CPUä¸“ç”¨é¢„æµ‹å™¨...")
        print(f"ğŸ’» å¼ºåˆ¶ä½¿ç”¨CPUè®¾å¤‡")
        
        # å¼ºåˆ¶æ¸…ç†å†…å­˜
        force_memory_cleanup()
        
        # åˆ›å»ºé¢„æµ‹å™¨ï¼Œå¼ºåˆ¶ä½¿ç”¨CPU
        print("ğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹åˆ°CPU...")
        self.predictor = None
        self._load_model(model_path)
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ!")
    
    def _load_model(self, model_path):
        """åŠ è½½æ¨¡å‹åˆ°CPU"""
        try:
            # å¦‚æœä¹‹å‰æœ‰æ¨¡å‹ï¼Œå…ˆæ¸…ç†
            if self.predictor is not None:
                del self.predictor
                force_memory_cleanup()
            
            from predict_timeseries_v2 import TimeSeriesPredictorV2
            
            # å¼ºåˆ¶ä½¿ç”¨CPU
            self.predictor = TimeSeriesPredictorV2(model_path=model_path, device='cpu')
            print("  âœ“ æ¨¡å‹å·²åŠ è½½åˆ°CPU")
                
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def predict_single_file_cpu(self, csv_path, bands, start_timestamp, end_timestamp, 
                               use_len, prediction_steps, output_dir, timestamp_col='timestamp'):
        """
        CPUå•æ–‡ä»¶é¢„æµ‹
        
        Args:
            csv_path: CSVæ–‡ä»¶è·¯å¾„
            bands: é¢„æµ‹æ³¢æ®µåˆ—è¡¨
            start_timestamp: å¼€å§‹æ—¶é—´æˆ³
            end_timestamp: ç»“æŸæ—¶é—´æˆ³
            use_len: ç”¨äºé¢„æµ‹çš„é•¿åº¦
            prediction_steps: é¢„æµ‹æ­¥æ•°
            output_dir: è¾“å‡ºç›®å½•
            timestamp_col: æ—¶é—´æˆ³åˆ—å
            
        Returns:
            dict: é¢„æµ‹ç»“æœ
        """
        print(f"\nğŸ“ å¼€å§‹é¢„æµ‹æ–‡ä»¶: {os.path.basename(csv_path)}")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ’» ä½¿ç”¨è®¾å¤‡: CPU")
        
        try:
            # é¢„æµ‹å‰æ¸…ç†å†…å­˜
            force_memory_cleanup()
            
            # è¿è¡Œé¢„æµ‹
            results = self.predictor.run_prediction(
                csv_path=csv_path,
                bands=bands,
                start_timestamp=start_timestamp,
                end_timestamp=end_timestamp,
                use_len=use_len,
                prediction_steps=prediction_steps,
                timestamp_col=timestamp_col,
                save_plot=True,
                output_dir=output_dir
            )
            
            # é¢„æµ‹åæ¸…ç†å†…å­˜
            force_memory_cleanup()
            
            print(f"âœ… æ–‡ä»¶ {os.path.basename(csv_path)} é¢„æµ‹å®Œæˆ!")
            return results
            
        except Exception as e:
            print(f"âŒ æ–‡ä»¶ {os.path.basename(csv_path)} é¢„æµ‹å¤±è´¥: {str(e)}")
            # å‘ç”Ÿé”™è¯¯æ—¶å¼ºåˆ¶æ¸…ç†å†…å­˜
            force_memory_cleanup()
            return None
    
    def run_cpu_batch_prediction(self, folder_path, bands, start_timestamp, end_timestamp,
                                use_len=144, prediction_steps=1, timestamp_col='timestamp',
                                base_output_dir='./cpu_only_predictions',
                                batch_size=2, max_retries=2):
        """
        CPUæ‰¹é‡é¢„æµ‹
        
        Args:
            folder_path: è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
            bands: é¢„æµ‹æ³¢æ®µåˆ—è¡¨
            start_timestamp: å¼€å§‹æ—¶é—´æˆ³
            end_timestamp: ç»“æŸæ—¶é—´æˆ³
            use_len: ç”¨äºé¢„æµ‹çš„é•¿åº¦
            prediction_steps: é¢„æµ‹æ­¥æ•°
            timestamp_col: æ—¶é—´æˆ³åˆ—å
            base_output_dir: åŸºç¡€è¾“å‡ºç›®å½•
            batch_size: æ‰¹å¤„ç†å¤§å°ï¼ˆCPUå¯ä»¥å¤„ç†æ›´å¤šæ–‡ä»¶ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            dict: æ‰¹é‡é¢„æµ‹ç»“æœç»Ÿè®¡
        """
        print("ğŸš€ CPUä¸“ç”¨æ‰¹é‡é¢„æµ‹å¯åŠ¨")
        print("=" * 60)
        print(f"ğŸ“ è¾“å…¥æ–‡ä»¶å¤¹: {folder_path}")
        print(f"ğŸ¯ é¢„æµ‹æ³¢æ®µ: {bands}")
        print(f"â° æ—¶é—´èŒƒå›´: {start_timestamp} åˆ° {end_timestamp}")
        print(f"ğŸ“Š ä½¿ç”¨é•¿åº¦: {use_len}, é¢„æµ‹æ­¥æ•°: {prediction_steps}")
        print(f"ğŸ“¦ æ‰¹å¤„ç†å¤§å°: {batch_size}")
        print(f"ğŸ”„ æœ€å¤§é‡è¯•æ¬¡æ•°: {max_retries}")
        print(f"ğŸ’» å¼ºåˆ¶ä½¿ç”¨CPUè®¾å¤‡")
        
        # æŸ¥æ‰¾CSVæ–‡ä»¶
        import glob
        csv_files = []
        for pattern in ['*.csv', '*.CSV']:
            csv_files.extend(glob.glob(os.path.join(folder_path, pattern)))
            csv_files.extend(glob.glob(os.path.join(folder_path, '**', pattern), recursive=True))
        csv_files = sorted(list(set(csv_files)))
        
        if not csv_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•CSVæ–‡ä»¶!")
            return {}
        
        print(f"ğŸ“‹ æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(base_output_dir, exist_ok=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_files = len(csv_files)
        success_count = 0
        failed_count = 0
        results_summary = {}
        
        # åˆ†æ‰¹å¤„ç†æ–‡ä»¶
        for batch_start in range(0, total_files, batch_size):
            batch_end = min(batch_start + batch_size, total_files)
            batch_files = csv_files[batch_start:batch_end]
            
            print(f"\nğŸ”„ å¤„ç†æ‰¹æ¬¡ {batch_start//batch_size + 1}/{(total_files + batch_size - 1)//batch_size}")
            print(f"   æ–‡ä»¶ {batch_start + 1}-{batch_end}/{total_files}")
            
            # æ‰¹æ¬¡å¼€å§‹å‰æ¸…ç†å†…å­˜
            force_memory_cleanup()
            
            # å¤„ç†å½“å‰æ‰¹æ¬¡çš„æ–‡ä»¶
            for i, csv_path in enumerate(batch_files):
                file_index = batch_start + i + 1
                file_name = os.path.basename(csv_path)
                print(f"\n[{file_index}/{total_files}] å¤„ç†æ–‡ä»¶: {file_name}")
                
                # éªŒè¯æ–‡ä»¶
                try:
                    import pandas as pd
                    df = pd.read_csv(csv_path)
                    
                    # æ£€æŸ¥å¿…éœ€çš„åˆ—
                    if timestamp_col not in df.columns:
                        print(f"  âš  è·³è¿‡æ— æ•ˆæ–‡ä»¶: ç¼ºå°‘æ—¶é—´æˆ³åˆ— '{timestamp_col}'")
                        failed_count += 1
                        results_summary[file_name] = {
                            'status': 'failed',
                            'reason': f'ç¼ºå°‘æ—¶é—´æˆ³åˆ— {timestamp_col}'
                        }
                        continue
                    
                    # æ£€æŸ¥é¢„æµ‹æ³¢æ®µ
                    missing_bands = [band for band in bands if band not in df.columns]
                    if missing_bands:
                        print(f"  âš  è·³è¿‡æ— æ•ˆæ–‡ä»¶: ç¼ºå°‘æ³¢æ®µ {missing_bands}")
                        failed_count += 1
                        results_summary[file_name] = {
                            'status': 'failed',
                            'reason': f'ç¼ºå°‘æ³¢æ®µ {missing_bands}'
                        }
                        continue
                    
                    # æ£€æŸ¥æ•°æ®è¡Œæ•°
                    if len(df) < 10:
                        print(f"  âš  è·³è¿‡æ— æ•ˆæ–‡ä»¶: æ•°æ®è¡Œæ•°è¿‡å°‘ ({len(df)})")
                        failed_count += 1
                        results_summary[file_name] = {
                            'status': 'failed',
                            'reason': f'æ•°æ®è¡Œæ•°è¿‡å°‘ ({len(df)})'
                        }
                        continue
                        
                except Exception as e:
                    print(f"  âš  è·³è¿‡æ— æ•ˆæ–‡ä»¶: æ— æ³•è¯»å–æ–‡ä»¶ ({str(e)})")
                    failed_count += 1
                    results_summary[file_name] = {
                        'status': 'failed',
                        'reason': f'æ— æ³•è¯»å–æ–‡ä»¶: {str(e)}'
                    }
                    continue
                
                # ç”Ÿæˆè¾“å‡ºç›®å½•
                file_name_no_ext = os.path.splitext(file_name)[0]
                output_subdir = os.path.join(base_output_dir, f"{file_name_no_ext}_fire")
                
                # é‡è¯•æœºåˆ¶
                success = False
                for retry in range(max_retries):
                    try:
                        print(f"  ğŸ”„ å°è¯• {retry + 1}/{max_retries}")
                        
                        # é¢„æµ‹å•ä¸ªæ–‡ä»¶
                        result = self.predict_single_file_cpu(
                            csv_path=csv_path,
                            bands=bands,
                            start_timestamp=start_timestamp,
                            end_timestamp=end_timestamp,
                            use_len=use_len,
                            prediction_steps=prediction_steps,
                            output_dir=output_subdir,
                            timestamp_col=timestamp_col
                        )
                        
                        if result is not None:
                            success_count += 1
                            results_summary[file_name] = {
                                'status': 'success',
                                'output_dir': output_subdir,
                                'bands': list(result.keys()),
                                'retries': retry + 1
                            }
                            success = True
                            break
                        else:
                            print(f"    âš  é¢„æµ‹è¿”å›ç©ºç»“æœ")
                            
                    except Exception as e:
                        print(f"    âŒ å°è¯• {retry + 1} å¤±è´¥: {str(e)}")
                        if retry < max_retries - 1:
                            print(f"    â³ ç­‰å¾… 3 ç§’åé‡è¯•...")
                            time.sleep(3)
                            force_memory_cleanup()
                        else:
                            print(f"    ğŸ’€ æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†")
                
                if not success:
                    failed_count += 1
                    results_summary[file_name] = {
                        'status': 'failed',
                        'reason': f'æ‰€æœ‰ {max_retries} æ¬¡é‡è¯•éƒ½å¤±è´¥',
                        'output_dir': output_subdir
                    }
            
            # æ‰¹æ¬¡å¤„ç†å®Œæˆåæ¸…ç†å†…å­˜
            print(f"\nğŸ§¹ æ‰¹æ¬¡ {batch_start//batch_size + 1} å®Œæˆï¼Œæ¸…ç†å†…å­˜...")
            force_memory_cleanup()
            
            # æ˜¾ç¤ºå½“å‰è¿›åº¦
            current_success_rate = success_count / (success_count + failed_count) * 100 if (success_count + failed_count) > 0 else 0
            print(f"ğŸ“Š å½“å‰è¿›åº¦: {success_count + failed_count}/{total_files} ({current_success_rate:.1f}% æˆåŠŸç‡)")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        print("\n" + "=" * 60)
        print("âœ… CPUä¸“ç”¨æ‰¹é‡é¢„æµ‹å®Œæˆ!")
        print("=" * 60)
        print(f"ğŸ“ˆ æˆåŠŸ: {success_count}/{total_files}")
        print(f"ğŸ“Š æˆåŠŸç‡: {success_count/total_files*100:.1f}%")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {base_output_dir}")
        
        # ä¿å­˜æ€»ç»“æŠ¥å‘Š
        import pandas as pd
        summary_data = []
        for file_name, info in results_summary.items():
            summary_data.append({
                'file_name': file_name,
                'status': info['status'],
                'output_dir': info.get('output_dir', ''),
                'bands': ', '.join(info.get('bands', [])),
                'reason': info.get('reason', ''),
                'retries': info.get('retries', 0)
            })
        
        summary_df = pd.DataFrame(summary_data)
        summary_file = os.path.join(base_output_dir, 'cpu_only_summary.csv')
        summary_df.to_csv(summary_file, index=False)
        print(f"ğŸ“‹ æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜åˆ°: {summary_file}")
        
        return results_summary

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¥ CPUä¸“ç”¨æ—¶é—´åºåˆ—æ‰¹é‡é¢„æµ‹å·¥å…·")
    print("=" * 60)
    print("ğŸ’¡ æ­¤å·¥å…·ä¸“é—¨ç”¨äºGPUå†…å­˜ä¸è¶³çš„æƒ…å†µ")
    print("ğŸ’» å¼ºåˆ¶ä½¿ç”¨CPUè¿›è¡Œé¢„æµ‹ï¼Œé¿å…GPUå†…å­˜é—®é¢˜")
    print("=" * 60)
    
    # è·å–ç”¨æˆ·è¾“å…¥
    print("\nè¯·è¾“å…¥é¢„æµ‹å‚æ•°:")
    
    # è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
    folder_path = input("ğŸ“ è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„: ").strip()
    if not folder_path:
        print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ–‡ä»¶å¤¹è·¯å¾„")
        return
    
    # é¢„æµ‹æ³¢æ®µ
    bands_input = input("ğŸ¯ é¢„æµ‹æ³¢æ®µ (ç”¨ç©ºæ ¼åˆ†éš”ï¼Œå¦‚: albedo_01 tbb_07): ").strip()
    if not bands_input:
        print("âŒ è¯·è¾“å…¥é¢„æµ‹æ³¢æ®µ")
        return
    bands = bands_input.split()
    
    # æ—¶é—´èŒƒå›´
    start_time = input("â° å¼€å§‹æ—¶é—´ (æ ¼å¼: YYYY-MM-DD HH:MM:SS): ").strip()
    if not start_time:
        print("âŒ è¯·è¾“å…¥å¼€å§‹æ—¶é—´")
        return
    
    end_time = input("â° ç»“æŸæ—¶é—´ (æ ¼å¼: YYYY-MM-DD HH:MM:SS): ").strip()
    if not end_time:
        print("âŒ è¯·è¾“å…¥ç»“æŸæ—¶é—´")
        return
    
    # å¯é€‰å‚æ•°
    use_len_input = input("ğŸ“Š ä½¿ç”¨é•¿åº¦ (é»˜è®¤144ï¼ŒæŒ‰å›è½¦ä½¿ç”¨é»˜è®¤å€¼): ").strip()
    use_len = int(use_len_input) if use_len_input else 144
    
    prediction_steps_input = input("ğŸ”® é¢„æµ‹æ­¥æ•° (é»˜è®¤1ï¼ŒæŒ‰å›è½¦ä½¿ç”¨é»˜è®¤å€¼): ").strip()
    prediction_steps = int(prediction_steps_input) if prediction_steps_input else 1
    
    batch_size_input = input("ğŸ“¦ æ‰¹å¤„ç†å¤§å° (é»˜è®¤2ï¼ŒæŒ‰å›è½¦ä½¿ç”¨é»˜è®¤å€¼): ").strip()
    batch_size = int(batch_size_input) if batch_size_input else 2
    
    max_retries_input = input("ğŸ”„ æœ€å¤§é‡è¯•æ¬¡æ•° (é»˜è®¤2ï¼ŒæŒ‰å›è½¦ä½¿ç”¨é»˜è®¤å€¼): ").strip()
    max_retries = int(max_retries_input) if max_retries_input else 2
    
    # ç¡®è®¤å‚æ•°
    print("\nğŸ“‹ é¢„æµ‹å‚æ•°ç¡®è®¤:")
    print(f"  è¾“å…¥æ–‡ä»¶å¤¹: {folder_path}")
    print(f"  é¢„æµ‹æ³¢æ®µ: {', '.join(bands)}")
    print(f"  æ—¶é—´èŒƒå›´: {start_time} åˆ° {end_time}")
    print(f"  ä½¿ç”¨é•¿åº¦: {use_len}")
    print(f"  é¢„æµ‹æ­¥æ•°: {prediction_steps}")
    print(f"  è®¡ç®—è®¾å¤‡: CPU (å¼ºåˆ¶)")
    print(f"  æ‰¹å¤„ç†å¤§å°: {batch_size}")
    print(f"  æœ€å¤§é‡è¯•æ¬¡æ•°: {max_retries}")
    
    confirm = input("\nç¡®è®¤å¼€å§‹é¢„æµ‹? (y/n): ").strip().lower()
    if confirm != 'y':
        print("âŒ ç”¨æˆ·å–æ¶ˆé¢„æµ‹")
        return
    
    # åˆ›å»ºCPUä¸“ç”¨é¢„æµ‹å™¨
    predictor = CPUOnlyBatchPredictor()
    
    # è¿è¡Œé¢„æµ‹
    results = predictor.run_cpu_batch_prediction(
        folder_path=folder_path,
        bands=bands,
        start_timestamp=start_time,
        end_timestamp=end_time,
        use_len=use_len,
        prediction_steps=prediction_steps,
        batch_size=batch_size,
        max_retries=max_retries
    )
    
    if results:
        print("\nğŸ‰ é¢„æµ‹å®Œæˆ! è¯·æŸ¥çœ‹è¾“å‡ºç›®å½•ä¸­çš„ç»“æœæ–‡ä»¶ã€‚")

if __name__ == "__main__":
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        # å‘½ä»¤è¡Œæ¨¡å¼
        if len(sys.argv) < 5:
            print("ç”¨æ³•: python batch_predict_cpu_only.py <æ–‡ä»¶å¤¹è·¯å¾„> <æ³¢æ®µ1 æ³¢æ®µ2...> <å¼€å§‹æ—¶é—´> <ç»“æŸæ—¶é—´> [ä½¿ç”¨é•¿åº¦] [é¢„æµ‹æ­¥æ•°] [æ‰¹å¤„ç†å¤§å°] [é‡è¯•æ¬¡æ•°]")
            print("ç¤ºä¾‹: python batch_predict_cpu_only.py './data' 'albedo_01 tbb_07' '2022-10-15 01:00:00' '2022-10-16 01:00:00' 144 1 2 2")
            sys.exit(1)
        
        folder_path = sys.argv[1]
        bands = sys.argv[2].split()
        start_time = sys.argv[3]
        end_time = sys.argv[4]
        use_len = int(sys.argv[5]) if len(sys.argv) > 5 else 144
        prediction_steps = int(sys.argv[6]) if len(sys.argv) > 6 else 1
        batch_size = int(sys.argv[7]) if len(sys.argv) > 7 else 2
        max_retries = int(sys.argv[8]) if len(sys.argv) > 8 else 2
        
        # åˆ›å»ºCPUä¸“ç”¨é¢„æµ‹å™¨
        predictor = CPUOnlyBatchPredictor()
        
        # è¿è¡Œé¢„æµ‹
        results = predictor.run_cpu_batch_prediction(
            folder_path=folder_path,
            bands=bands,
            start_timestamp=start_time,
            end_timestamp=end_time,
            use_len=use_len,
            prediction_steps=prediction_steps,
            batch_size=batch_size,
            max_retries=max_retries
        )
    else:
        # äº¤äº’å¼æ¨¡å¼
        main() 