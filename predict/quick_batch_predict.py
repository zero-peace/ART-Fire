#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Âø´ÈÄüÊâπÈáèÈ¢ÑÊµãËÑöÊú¨
Êèê‰æõÁÆÄÂåñÁöÑÊâπÈáèÈ¢ÑÊµãÊé•Âè£ÔºåÈÄÇÂêàÂø´ÈÄü‰ΩøÁî®
"""

import os
import sys
import torch
from batch_predict import BatchPredictor

def quick_batch_predict(folder_path, bands, start_time, end_time, 
                       use_len=144, prediction_steps=3, device='auto'):
    """
    Âø´ÈÄüÊâπÈáèÈ¢ÑÊµãÂáΩÊï∞
    
    Args:
        folder_path: ËæìÂÖ•Êñá‰ª∂Â§πË∑ØÂæÑ
        bands: È¢ÑÊµãÊ≥¢ÊÆµÂàóË°®
        start_time: ÂºÄÂßãÊó∂Èó¥ (Ê†ºÂºè: 'YYYY-MM-DD HH:MM:SS')
        end_time: ÁªìÊùüÊó∂Èó¥ (Ê†ºÂºè: 'YYYY-MM-DD HH:MM:SS')
        use_len: Áî®‰∫éÈ¢ÑÊµãÁöÑÈïøÂ∫¶ÔºåÈªòËÆ§144Ôºà24Â∞èÊó∂Ôºâ
        prediction_steps: È¢ÑÊµãÊ≠•Êï∞ÔºåÈªòËÆ§3
        device: ËÆ°ÁÆóËÆæÂ§áÔºå'auto'Ëá™Âä®ÈÄâÊã©Ôºå'cpu'Êàñ'cuda'
    
    Returns:
        dict: È¢ÑÊµãÁªìÊûúÁªüËÆ°
    """
    
    print("üöÄ Âø´ÈÄüÊâπÈáèÈ¢ÑÊµãÂêØÂä®")
    print("=" * 50)
    
    # Ê£ÄÊü•ËæìÂÖ•Êñá‰ª∂Â§π
    if not os.path.exists(folder_path):
        print(f"‚ùå ÈîôËØØ: ËæìÂÖ•Êñá‰ª∂Â§π‰∏çÂ≠òÂú®: {folder_path}")
        return None
    
    # Ëá™Âä®ÈÄâÊã©ËÆæÂ§á
    if device == 'auto':
        import torch
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    print(f"üìÅ ËæìÂÖ•Êñá‰ª∂Â§π: {folder_path}")
    print(f"üéØ È¢ÑÊµãÊ≥¢ÊÆµ: {', '.join(bands)}")
    print(f"‚è∞ Êó∂Èó¥ËåÉÂõ¥: {start_time} Âà∞ {end_time}")
    print(f"üìä ‰ΩøÁî®ÈïøÂ∫¶: {use_len} ({(use_len*10)/60:.1f}Â∞èÊó∂)")
    print(f"üîÆ È¢ÑÊµãÊ≠•Êï∞: {prediction_steps}")
    print(f"üíª ‰ΩøÁî®ËÆæÂ§á: {device}")
    
    # ÁîüÊàêËæìÂá∫ÁõÆÂΩï
    folder_name = os.path.basename(folder_path)
    output_dir = f'./{folder_name}_batch_predictions'
    
    try:
        # ÂàõÂª∫ÊâπÈáèÈ¢ÑÊµãÂô®
        print("\nüîß ÂàùÂßãÂåñÈ¢ÑÊµãÂô®...")
        batch_predictor = BatchPredictor(device=device)
        
        # ËøêË°åÊâπÈáèÈ¢ÑÊµã
        print("üöÄ ÂºÄÂßãÊâπÈáèÈ¢ÑÊµã...")
        results = batch_predictor.run_batch_prediction(
            folder_path=folder_path,
            bands=bands,
            start_timestamp=start_time,
            end_timestamp=end_time,
            use_len=use_len,
            prediction_steps=prediction_steps,
            base_output_dir=output_dir
        )
        
        # ÊòæÁ§∫ÁªìÊûú
        success_count = sum(1 for info in results.values() if info['status'] == 'success')
        total_count = len(results)
        
        print("\n" + "=" * 50)
        print("‚úÖ ÊâπÈáèÈ¢ÑÊµãÂÆåÊàê!")
        print("=" * 50)
        print(f"üìà ÊàêÂäü: {success_count}/{total_count}")
        print(f"üìä ÊàêÂäüÁéá: {success_count/total_count*100:.1f}%")
        print(f"üìÅ ÁªìÊûú‰øùÂ≠òÂú®: {output_dir}")
        
        return results
        
    except Exception as e:
        print(f"‚ùå È¢ÑÊµãËøáÁ®ã‰∏≠Âá∫Áé∞ÈîôËØØ: {str(e)}")
        return None

def main():
    """‰∏ªÂáΩÊï∞ - ‰∫§‰∫íÂºè‰ΩøÁî®"""
    
    print("üî• Êó∂Èó¥Â∫èÂàóÊâπÈáèÈ¢ÑÊµãÂ∑•ÂÖ∑")
    print("=" * 50)
    
    # Ëé∑ÂèñÁî®Êà∑ËæìÂÖ•
    print("\nËØ∑ËæìÂÖ•È¢ÑÊµãÂèÇÊï∞:")
    
    # ËæìÂÖ•Êñá‰ª∂Â§πË∑ØÂæÑ
    folder_path = input("üìÅ ËæìÂÖ•Êñá‰ª∂Â§πË∑ØÂæÑ: ").strip()
    if not folder_path:
        print("‚ùå ËØ∑ËæìÂÖ•ÊúâÊïàÁöÑÊñá‰ª∂Â§πË∑ØÂæÑ")
        return
    
    # È¢ÑÊµãÊ≥¢ÊÆµ
    bands_input = input("üéØ È¢ÑÊµãÊ≥¢ÊÆµ (Áî®Á©∫Ê†ºÂàÜÈöîÔºåÂ¶Ç: albedo_01 tbb_07): ").strip()
    if not bands_input:
        print("‚ùå ËØ∑ËæìÂÖ•È¢ÑÊµãÊ≥¢ÊÆµ")
        return
    bands = bands_input.split()
    
    # Êó∂Èó¥ËåÉÂõ¥
    start_time = input("‚è∞ ÂºÄÂßãÊó∂Èó¥ (Ê†ºÂºè: YYYY-MM-DD HH:MM:SS): ").strip()
    if not start_time:
        print("‚ùå ËØ∑ËæìÂÖ•ÂºÄÂßãÊó∂Èó¥")
        return
    
    end_time = input("‚è∞ ÁªìÊùüÊó∂Èó¥ (Ê†ºÂºè: YYYY-MM-DD HH:MM:SS): ").strip()
    if not end_time:
        print("‚ùå ËØ∑ËæìÂÖ•ÁªìÊùüÊó∂Èó¥")
        return
    
    # ÂèØÈÄâÂèÇÊï∞
    use_len_input = input("üìä ‰ΩøÁî®ÈïøÂ∫¶ (ÈªòËÆ§144ÔºåÊåâÂõûËΩ¶‰ΩøÁî®ÈªòËÆ§ÂÄº): ").strip()
    use_len = int(use_len_input) if use_len_input else 144
    
    prediction_steps_input = input("üîÆ È¢ÑÊµãÊ≠•Êï∞ (ÈªòËÆ§3ÔºåÊåâÂõûËΩ¶‰ΩøÁî®ÈªòËÆ§ÂÄº): ").strip()
    prediction_steps = int(prediction_steps_input) if prediction_steps_input else 3
    
    device_input = input("üíª ËÆ°ÁÆóËÆæÂ§á (auto/cpu/cudaÔºåÈªòËÆ§auto): ").strip()
    device = device_input if device_input else 'auto'
    
    # Á°ÆËÆ§ÂèÇÊï∞
    print("\nüìã È¢ÑÊµãÂèÇÊï∞Á°ÆËÆ§:")
    print(f"  ËæìÂÖ•Êñá‰ª∂Â§π: {folder_path}")
    print(f"  È¢ÑÊµãÊ≥¢ÊÆµ: {', '.join(bands)}")
    print(f"  Êó∂Èó¥ËåÉÂõ¥: {start_time} Âà∞ {end_time}")
    print(f"  ‰ΩøÁî®ÈïøÂ∫¶: {use_len}")
    print(f"  È¢ÑÊµãÊ≠•Êï∞: {prediction_steps}")
    print(f"  ËÆ°ÁÆóËÆæÂ§á: {device}")
    
    confirm = input("\nÁ°ÆËÆ§ÂºÄÂßãÈ¢ÑÊµã? (y/n): ").strip().lower()
    if confirm != 'y':
        print("‚ùå Áî®Êà∑ÂèñÊ∂àÈ¢ÑÊµã")
        return
    
    # ËøêË°åÈ¢ÑÊµã
    results = quick_batch_predict(
        folder_path=folder_path,
        bands=bands,
        start_time=start_time,
        end_time=end_time,
        use_len=use_len,
        prediction_steps=prediction_steps,
        device=device
    )
    
    if results:
        print("\nüéâ È¢ÑÊµãÂÆåÊàê! ËØ∑Êü•ÁúãËæìÂá∫ÁõÆÂΩï‰∏≠ÁöÑÁªìÊûúÊñá‰ª∂„ÄÇ")

if __name__ == "__main__":
    # Ê£ÄÊü•ÂëΩ‰ª§Ë°åÂèÇÊï∞
    if len(sys.argv) > 1:
        # ÂëΩ‰ª§Ë°åÊ®°Âºè
        if len(sys.argv) < 5:
            print("Áî®Ê≥ï: python quick_batch_predict.py <Êñá‰ª∂Â§πË∑ØÂæÑ> <Ê≥¢ÊÆµ1 Ê≥¢ÊÆµ2...> <ÂºÄÂßãÊó∂Èó¥> <ÁªìÊùüÊó∂Èó¥> [‰ΩøÁî®ÈïøÂ∫¶] [È¢ÑÊµãÊ≠•Êï∞] [ËÆæÂ§á]")
            print("Á§∫‰æã: python quick_batch_predict.py './data' 'albedo_01 tbb_07' '2022-10-15 01:00:00' '2022-10-16 01:00:00' 144 3 cuda")
            sys.exit(1)
        
        folder_path = sys.argv[1]
        bands = sys.argv[2].split()
        start_time = sys.argv[3]
        end_time = sys.argv[4]
        use_len = int(sys.argv[5]) if len(sys.argv) > 5 else 144
        prediction_steps = int(sys.argv[6]) if len(sys.argv) > 6 else 3
        device = sys.argv[7] if len(sys.argv) > 7 else 'auto'
        
        results = quick_batch_predict(
            folder_path=folder_path,
            bands=bands,
            start_time=start_time,
            end_time=end_time,
            use_len=use_len,
            prediction_steps=prediction_steps,
            device=device
        )
    else:
        # ‰∫§‰∫íÂºèÊ®°Âºè
        main() 